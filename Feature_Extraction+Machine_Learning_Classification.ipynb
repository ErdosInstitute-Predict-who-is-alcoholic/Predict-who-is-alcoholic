{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages needed for this script \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from scipy import stats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load arrays\n",
    "data_array = np.load('Data/data_array.npy') \n",
    "label_array= np.load('Data/label_array.npy')\n",
    "group_array= np.load('Data/group_array.npy')\n",
    "epochs_times=np.load('Data/epochs_times.npy')\n",
    "print(data_array.shape, label_array.shape, group_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature selection of mean channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = []\n",
    "for x in data_array:\n",
    "    channels.append(np.mean(x, axis=-1))\n",
    "channels_array=np.array(channels) #X\n",
    "channels_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train set of Means \n",
    "train = pd.DataFrame(channels_array, columns=['AF1', 'AF2', 'AF7', 'AF8', 'AFZ', 'C1', 'C2', 'C3', 'C4',\n",
    "       'C5', 'C6', 'CP1', 'CP2', 'CP3', 'CP4', 'CP5', 'CP6', 'CPZ', 'CZ', 'F1',\n",
    "       'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'FC1', 'FC2', 'FC3', 'FC4',\n",
    "       'FC5', 'FC6', 'FCZ', 'FP1', 'FP2', 'FPZ', 'FT7', 'FT8', 'FZ', 'O1',\n",
    "       'O2', 'OZ', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'PO1',\n",
    "       'PO2', 'PO7', 'PO8', 'POZ', 'PZ', 'T7', 'T8', 'TP7', 'TP8', 'X', 'Y',\n",
    "       'nd', 'stimulus'])\n",
    "train['label'] = label_array\n",
    "train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X,y, model):\n",
    "    x = X.values\n",
    "    model.fit(x, y)\n",
    "    scores = pd.DataFrame({'Feature': X.columns, \n",
    "                          'Importance Score': model.feature_importances_})\n",
    "    return scores.sort_values('Importance Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:,:-2]\n",
    "y = train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selecttion Extra Trees Classifier \n",
    "feature_selection(X,y, ExtraTreesClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection Random Forest Classifier\n",
    "feature_selection(X,y, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualization\n",
    "list_of_columns = ['P1', 'CP2', 'FC2', 'FZ','CP2']\n",
    "\n",
    "# selection of 2 columns at a time\n",
    "combo_of_columns = list(combinations(list_of_columns,2))\n",
    "\n",
    "repeat_labels = np.array(np.unique(label_array).tolist()*len(combo_of_columns)).reshape((len(combo_of_columns),2))\n",
    "\n",
    "fig, axes = plt.subplots(len(combo_of_columns))\n",
    "fig.set_figheight(50)\n",
    "\n",
    "for idx, (features, cl) in enumerate(zip(combo_of_columns, repeat_labels)):\n",
    "    for cls in cl:\n",
    "        axes[idx].scatter(x=train.loc[train['label'] == cls,\n",
    "        features[0]], y=train.loc[train['label']==cls, features[1]])\n",
    "        axes[idx].set_title('Plot of {0} against {1}'.format(features[1], features[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting environment for Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(x):\n",
    "    return np.mean(x, axis=-1)\n",
    "def std(x):\n",
    "    return np.std(x, axis=-1)\n",
    "def ptp(x):\n",
    "    return np.ptp(x, axis=-1)\n",
    "def var(x):\n",
    "    return np.var(x, axis=-1)\n",
    "def minim(x):\n",
    "    return np.min(x, axis=-1)\n",
    "def maxim(x):\n",
    "    return np.max(x, axis=-1)\n",
    "def argminim(x):\n",
    "    return np.argmin(x, axis=-1)\n",
    "def argmaxim(x):\n",
    "    return np.argmax(x, axis=-1)\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2, axis=-1))\n",
    "def abs_diff_signal(x):\n",
    "    return np.sum(np.abs(np.diff(x, axis=-1)), axis=-1)\n",
    "def skewness(x):\n",
    "    return stats.skew(x, axis=-1)\n",
    "def kurtosis(x):\n",
    "    return stats.kurtosis(x, axis=-1)\n",
    "\n",
    "def concatenate_features(x):\n",
    "    return np.concatenate((mean(x), std(x), ptp(x), var(x), minim(x), maxim(x),\n",
    "                          argminim(x), argmaxim(x), rms(x), abs_diff_signal(x),\n",
    "                          skewness(x), kurtosis(x)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for d in data_array:\n",
    "    features.append(concatenate_features(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array=np.array(features) #X\n",
    "features_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mne.decoding import SlidingEstimator, cross_val_multiscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_method_list = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "#Creates pipeline for each classifier and returns a dictionary with metrics used for analysis\n",
    "def model_metric (classifier, X, y):\n",
    "    scoring_dictionary = {}\n",
    "    \n",
    "    clf = make_pipeline(StandardScaler(), classifier)\n",
    "    \n",
    "    for scoring_method in scoring_method_list:\n",
    "        time_decod = SlidingEstimator(clf, n_jobs=1, scoring=scoring_method, verbose=True)\n",
    "        scores = cross_val_multiscore(time_decod, X, y,  cv=3, n_jobs=1) #groups=group_array,\n",
    "        scoring_dictionary.update ( {scoring_method:np.mean(scores, axis=0) })\n",
    "        \n",
    "    return scoring_dictionary\n",
    "\n",
    "\n",
    "#Unpacks a dictionary connecting each classifier to the dictionary of theirs metrics into a one-layer dictionary for dataframe use\n",
    "\n",
    "def unpack_results(classifier_results_dictionary):\n",
    "    unpacked_classifier_results = {}\n",
    "\n",
    "    for classifier_name in classifier_results_dictionary:\n",
    "        for scoring_method in classifier_results_dictionary[classifier_name]:\n",
    "            unpacked_classifier_results.update({'{} {}'.format(classifier_name, scoring_method):classifier_results_dictionary[classifier_name][scoring_method]})\n",
    "\n",
    "    return unpacked_classifier_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAssed all data through classifier - raw test\n",
    "features_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list = [LogisticRegression(solver='liblinear'), RandomForestClassifier(), SVC(kernel = 'linear', C = 1.0) ]\n",
    "classifier_name_list = ['Logistic Regression', 'Random Forest', 'SVC']\n",
    "classifier_zip_list = zip (classifier_list,classifier_name_list)\n",
    "\n",
    "classifier_results_dictionary = {}\n",
    "\n",
    "for classifier_info in classifier_zip_list:\n",
    "    classifier, classifier_name = classifier_info\n",
    "    \n",
    "    #try:\n",
    "    classifier_results_dictionary.update ({classifier_name:model_metric (classifier, data_array, label_array)})\n",
    "    print ('Classifier {} is complete!'.format(classifier_name))\n",
    "    #except:\n",
    "    print ('Classifier {} has failed!!!'.format(classifier_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpacked_classifier_results = unpack_results (classifier_results_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passed data through - select channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_list = ['AF1', 'AF2', 'AF7', 'AF8', 'AFZ', 'C1', 'C2', 'C3', 'C4',\n",
    "       'C5', 'C6', 'CP1', 'CP2', 'CP3', 'CP4', 'CP5', 'CP6', 'CPZ', 'CZ', 'F1',\n",
    "       'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'FC1', 'FC2', 'FC3', 'FC4',\n",
    "       'FC5', 'FC6', 'FCZ', 'FP1', 'FP2', 'FPZ', 'FT7', 'FT8', 'FZ', 'O1',\n",
    "       'O2', 'OZ', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'PO1',\n",
    "       'PO2', 'PO7', 'PO8', 'POZ', 'PZ', 'T7', 'T8', 'TP7', 'TP8', 'X', 'Y',\n",
    "       'nd', 'stimulus']\n",
    "list_of_columns = ['P1', 'CP2', 'FC2', 'FZ','POZ']\n",
    "col_loc = [index for index, col_name in enumerate (channel_list) if col_name in list_of_columns]\n",
    "\n",
    "X = data_array[:,col_loc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list = [LogisticRegression(solver='liblinear'), RandomForestClassifier(), SVC(kernel = 'linear', C = 1.0) ]\n",
    "classifier_name_list = ['Logistic Regression', 'Random Forest', 'SVC']\n",
    "classifier_zip_list = zip (classifier_list,classifier_name_list)\n",
    "\n",
    "classifier_results_dictionary = {}\n",
    "\n",
    "for classifier_info in classifier_zip_list:\n",
    "    classifier, classifier_name = classifier_info\n",
    "    \n",
    "    try:\n",
    "        classifier_results_dictionary.update({classifier_name:model_metric (classifier, X, label_array)})\n",
    "        print ('Classifier {} is complete!'.format(classifier_name))\n",
    "    except:\n",
    "        print ('Classifier {} has failed!!!'.format(classifier_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpacking data for 5 channels\n",
    "\n",
    "unpacked_classifier_results = unpack_results (classifier_results_dictionary)\n",
    "all_channels_metrics = pd.DataFrame.from_dict (unpacked_classifier_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpacking data for 5 channels\n",
    "all_channels_metrics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_channels_metrics = pd.DataFrame.from_dict (unpacked_classifier_results)\n",
    "all_channels_metrics.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random forest using all channels\n",
    "clf = RandomForestClassifier()\n",
    "gkf = GroupKFold(5)\n",
    "pipe=Pipeline([('scaler', StandardScaler()), ('clf', clf)])\n",
    "param_grid={'clf__max_features':['sqrt','log2', None],\n",
    "        'clf__min_samples_leaf':[1, 2, 3],\n",
    "        'clf__max_depth':[None]}\n",
    "\n",
    "gscv=GridSearchCV(pipe, param_grid, cv=gkf, n_jobs=12)\n",
    "gscv.fit(features_array, label_array, groups=group_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels_after_hyper = pd.DataFrame.from_dict(classifier_results_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
